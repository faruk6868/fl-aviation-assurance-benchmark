Section,Subsection,req_ID,Title,Requirement_Statement,Normative_Clauses_ID
R.D. Data & Governance,R.D.1 ODD Definition and Coverage,R.D.1.1,Define ODD Parameters and Operational Domain,"The AI/ML system shall operate only within an Operational Design Domain (ODD) whose parameters are explicitly specified, traceable to the Operational Domain (OD), and fully documented in the versioned and approved Concept of Operations (ConOps).","EASA-002, EASA-012"
,,R.D.1.2,ODD Coverage Assurance,"The dataset used for development and verification shall sufficiently and representatively cover the defined ODD, including edge cases and corner cases identified to assure safety of the intended functionality.","STD-001, EASA-017"
,R.D.2 Data Quality and Integrity,R.D.2.1,Data Quality Requirements,"Data used across the AI/ML lifecycle shall meet documented Data Quality Requirements (DQRs) for relevance, origin, format, accuracy, traceability, integrity, completeness, and representativeness.","EASA-013, EASA-015, EASA-41, STD-005"
,,R.D.2.2,Data Source Identification and Collection,"The organization shall identify data sources and collect data per ODD while meeting Data Quality Requirements, with documented provenance and traceability.","EASA-015, EASA-013, STD-005"
,,R.D.2.3,Data Verification and Validation,"The organization shall verify and validate data against the DQRs, performing data verification for ODD appropriateness and dataset adequacy, producing objective evidence that completeness and representativeness criteria are satisfied before training.","EASA-017, STD-001"
,,R.D.2.4,Dataset Separation and Independence,"Training, validation, test, and certification holdout datasets shall be distributed into strictly independent sets with controls preventing cross-contamination and data leakage, supported by auditable safeguards.","FAA-009, EASA-016, FDA-003, "
,,R.D.2.5,Requirements Validation,"All captured requirements (system, functional, and data quality requirements) shall be validated prior to development to ensure completeness, consistency, and feasibility.",EASA-014
,,R.D.2.6,Data Pre-processing and Feature Engineering,"The organization shall capture, document, and enforce all requirements on data to be pre-processed and engineered for the inference model in both development and operational phases.","EASA-041
"
,R.D.3 System Analysis and Design,R.D.3.1,Functional Analysis and Decomposition,"The organization shall perform functional analysis with functional decomposition and allocation, recognizing AI/ML uniqueness where learned implementation may break traditional hierarchical design links.","EASA-004, FAA-011"
,,R.D.3.2,AI Involvement Level Definition,The AI Involvement Level shall be defined to determine the appropriate level of assurance rigor required for the AI/ML system.,EASA-003
,,R.D.3.3,"Preliminary AI/ML Constituent Architecture	","The preliminary architecture of all AI/ML system constituents shall be described and maintained as a reference for all related safety assessments and learning assurance objectives.	","EASA-042
"
,,"R.D.3.4	","Derived Requirement Flowdown	","The organization shall document and provide evidence that all derived requirements (including those raised during safety support assessment) have been fully provided to (sub)system processes.	","EASA-043
"
,,"R.D.3.5	","Derived Requirements Validation	","The organization shall document, validate, and assess the impact of all derived requirements on the safety assessment and (sub)system requirements.	","EASA-044
"
,R.D.4 Governance and Trustworthiness,R.D.4.1,AI Trustworthiness Principles,"The AI/ML system shall be developed and assured to be trustworthy: safe, lawful, robust, ethical, and unbiased, using adapted safety assurance methods.","FAA-001, FAA-007"
,,R.D.4.2,Trustworthiness Building Blocks,"The organization shall integrate EASA's trustworthiness building blocks including analysis, assurance, human factors, and safety risk mitigation throughout the AI/ML system lifecycle.",EASA-001
,,R.D.4.3,Ethics-Based Trustworthiness Assessment,"The organization shall perform an ethics-based trustworthiness assessment for ML systems, ensuring compliance with national/EU data protection regulations.","EASA-007, EASA-008"
,R.D.5 Information Security,R.D.5.1,Identify Security Risks,"Information security risks, including AI/ML-specific threats (adversarial attacks, model extraction, data poisoning), shall be identified, assessed, and recorded with explicit linkage to mitigations.","EASA-036, FL-005"
,,R.D.5.2,Validate Security Controls,"Security controls addressing AI/ML-specific risks shall be validated for effectiveness prior to deployment, with mitigation strategies demonstrated.",EASA-037
,R.D.6 Federated Learning Data Characterization,R.D.6.1,Client Data Distribution Characterization,"For federated learning systems, the program shall characterize client-level data distributions across quantity skew, label/class skew, feature distribution shift, and temporal drift, quantifying the non-IID degree using standardized measures with a versioned registry per client cohort.",FL-001
R.M. Model Performance & Robustness,R.M.1 Safety-Linked Performance Validation,R.M.1.1,Safety Assessment Linkage,"Performance metrics and thresholds shall be linked to safety objectives and hazard analysis, with traceable allocation to false negative/false positive risks derived from functional hazard assessment.","STD-002, EASA-004"
,,R.M.1.2,Hazard-Driven Metric Prioritization,"The system shall prioritize metric targets according to hazard drivers, explicitly allocating stricter limits to false negatives when warranted by safety analysis.",STD-003
,,R.M.1.3,Trained Model Test Evaluation,"The trained model shall be evaluated on an independent test set, and verification results shall be documented with objective evidence for certification purposes.","EASA-020, STD-005"
,,R.M.1.4,Inference Model Test Evaluation,"The deployed inference artifact shall be evaluated on an independent test set representative of operational conditions, with documented evidence.",EASA-023
,,R.M.1.5,Generalization Bounds,Quantified generalization bounds with confidence intervals shall be provided to support claims of out-of-sample performance.,"EASA-019, FDA-004"
,,R.M.1.6,Statistical Confidence Reporting,Two-sided 95% confidence intervals shall be reported for all primary performance estimates used in assurance claims.,FDA-004
,,R.M.1.7,Cross-Population Performance Stability,"Model performance shall remain stable and acceptable across heterogeneous clients and participant groups, demonstrating safety and effectiveness for all intended users.","FDA-001, FDA-002"
,R.M.2 Robustness and Stability,R.M.2.1,Learning Management Requirements,"The organization shall capture requirements for learning management and training processes, including robustness and stability metrics with acceptable threshold levels.",EASA-018
,R.M.2 Robustness and Stability,R.M.2.2,Trained Model Stability Verification,"The trained model shall demonstrate performance stability across the full ODD, including validated operating regions and transitions, with stability verified through repeated testing.","EASA-021, STD-001"
,,R.M.2.3,Trained Model Robustness Under Adverse Conditions,"The trained model shall maintain acceptable performance under defined adverse training conditions, perturbations, and distribution shifts.",EASA-022
,,R.M.2.4,Inference Model Robustness Under Adverse Conditions,"The inference model shall maintain acceptable performance under defined adverse inference conditions, perturbations, and operational edge cases.",EASA-024
,,R.M.2.5,Stress Testing,"The system shall undergo stress testing from item-level to aircraft-level interfaces to detect anomalous behaviors, with corrective actions defined and implemented.",FAA-012
,"R.M.3 Model Bias and Reproducibility	","R.M.3.1	","Model Family Bias-Variance Management	","The bias-variance trade-off of selected model families shall be analyzed and evidence of reproducibility of model training shall be provided.	","EASA-045
"
,,"R.M.3.2	","Model Bias and Variance Conformance	","The estimated bias and variance of the selected model shall conform to the defined learning management requirements.	","EASA-046
"
,"R.M.4 Model Learning Stability	","R.M.4.1	","Learning Algorithm Stability Analysis	","The organization shall provide an analysis of the stability of all learning algorithms used in model training and refinement.	","EASA-047
"
,,"R.M.4.2	","Generalization Bound Verification	","The anticipated generalisation bounds for the model shall be verified using independent test data.	","EASA-048
"
,"R.M.5 Model Implementation Verification	","R.M.5.1	","Model Transformation Impact Assessment	","Model transformations (conversion, optimization, inference model development) performed post-training shall be verified to ensure they do not adversely alter defined model properties.	","EASA-049
"
,,"R.M.5.2	","Inference Model Stability Verification	","The organization shall perform and document the verification of the stability of the deployed inference model under representative operational scenarios.	","EASA-050
"
R.L. Lifecycle & Process Assurance,R.L.1 Configuration and Quality Management,R.L.1.1,Configuration Management,"All ML artifacts (datasets, model binaries, training configurations, code, hyperparameters) shall be under configuration management with versioning, change control, and reproducibility procedures.","STD-006, EASA-025"
,R.L.1 Configuration and Quality Management,R.L.1.2,Quality and Process Assurance,"The organization shall ensure quality and process assurance across the development lifecycle, with documented procedures and objective evidence of compliance.",EASA-026
,R.L.1 Configuration and Quality Management,R.L.1.3,Traceability,"The organization shall ensure bidirectional traceability from system/ML requirements to data artifacts, models, verification cases, and objective results to support certification review at the required assurance level.","STD-005, EASA-025"
,R.L.2 Learning Assurance Process,R.L.2.1,Learning Assurance Process Description,"The organization shall describe the proposed learning assurance process considering development assurance objectives, with explicit consideration of AI/ML-specific verification activities.",EASA-011
,R.L.2 Learning Assurance Process,R.L.2.2,Learning AI Change Process Certification,"For systems with learning capabilities, the organization shall certify the change process covering training, aggregation, validation, and deployment, with explicit approval gates.",FAA-010
,R.L.2 Learning Assurance Process,R.L.2.3,Locked AI Requirement,The AI algorithm shall be locked and not learn post-deployment. Online learning in operation shall be prohibited unless explicitly approved and re-assessed under a change control plan.,"FAA-008, EASA-035"
,R.L.3 Continuous Monitoring and Change Control,R.L.3.1,Operational Data Recording,The system shall identify which data must be recorded for continuous safety assessment and provide means to record operational data for post-operation analysis and explanation.,"EASA-005, EASA-031"
,R.L.3 Continuous Monitoring and Change Control,R.L.3.2,Continuous Safety Assessment,"The organization shall implement data-driven AI continuous safety assessment based on operational data, with defined triggers for intervention.",EASA-006
,R.L.3 Continuous Monitoring and Change Control,R.L.3.3,Input and Output Monitoring,Inputs (ODD bounds) and outputs (performance bounds) shall be monitored in operation with defined alert thresholds and escalation procedures.,EASA-038
,R.L.3 Continuous Monitoring and Change Control,R.L.3.4,Output Confidence Monitoring,"Output confidence shall be monitored and remain within specified operational limits, with alarms and mitigations enacted when thresholds are exceeded.",EASA-039
,R.L.3 Continuous Monitoring and Change Control,R.L.3.5,Metric Stability Monitoring,Performance metrics and their stability shall be continuously monitored to detect degradation or drift against design assumptions.,EASA-040
,R.L.3 Continuous Monitoring and Change Control,R.L.3.6,Lifecycle Performance and Data Shift Detection,"The organization shall detect shifts in input data distribution and performance over time across the total product lifecycle, enacting defined drift mitigation strategies.",FDA-005
,R.L.3 Continuous Monitoring and Change Control,R.L.3.7,Predetermined Change Control Plan,"A predetermined change control plan (PCCP) shall govern model retraining and updates, including regression validation, re-verification criteria, and approval workflows.",FDA-006
,R.L.3 Continuous Monitoring and Change Control,R.L.3.8,Certification Maintenance Workflows,"The system shall support certification maintenance by enabling secure data download, retest procedures, and drift monitoring workflows compatible with certification credit retention.",STD-004
,R.L.4 Model Reuse and COTS,R.L.4.1,Model Reuse Impact Assessment,"The organization shall perform an impact assessment when reusing pre-trained models or transfer learning, documenting assumptions, limitations, and re-verification activities.",EASA-027
,R.L.4 Model Reuse and COTS,R.L.4.2,COTS ML Function Analysis,"COTS ML functions shall be analyzed for applicable capabilities, with unused or out-of-scope functions deactivated or demonstrated to pose no safety impact.",EASA-028
R.E. Explainability,R.E.1 Explainability Requirements,R.E.1.1,Human-Understandable Explanations,"The AI/ML system shall provide human-understandable and context-relevant explanations of model scope, behavior, outputs, confidence/uncertainty, and limitations for the intended operators.",XAI-001
,R.E.1 Explainability Requirements,R.E.1.2,Feature Attribution Explanations,"The system shall produce feature attribution explanations with defined fidelity to the underlying model, quantitative stability across runs/seeds, and localization to relevant input regions.",XAI-002
,R.E.1 Explainability Requirements,R.E.1.3,Explanation Method Documentation,"The organization shall document attribution methods, configurations, data scope, and known limitations of the explainability approach.",XAI-003
,R.E.1 Explainability Requirements,R.E.1.4,Explanation Presentation,"Explanations shall be presented to end users in a clear, unambiguous form appropriate to the task, situation, and user expertise level.","EASA-032, EASA-033"
,R.E.1 Explainability Requirements,R.E.1.5,Explanation Validity,"The validity of each specified explanation type shall be ensured for each relevant model output, with verification evidence documented.",EASA-034
R.H. Human Factors,R.H.1 Situation Awareness,R.H.1.1,Individual Situation Awareness,"The system design shall reinforce individual situation awareness, ensuring operators maintain appropriate understanding of system state and operational context.",EASA-029
,R.H.1 Situation Awareness,R.H.1.2,Shared Situation Awareness,The system shall enable and support shared situation awareness across crew members and operational stakeholders.,EASA-030
,R.H.2 User Competency and Training,R.H.2.1,User Competency Requirements,The organization shall identify new competencies required for users interacting with the AI/ML system and mitigate training gaps through documented training programs.,EASA-009
,R.H.2 User Competency and Training,R.H.2.2,De-Skilling Risk Assessment,The organization shall assess the risk of operator de-skilling due to automation and mitigate identified risks through training and operational procedures.,EASA-010
R.V. Verification & Validation,R.V.1 V&V Process Requirements,R.V.1.1,Comprehensive V&V Objectives,"Verification and validation activities shall address explainability, predictability, auditability, and traceability objectives appropriate to the assurance level.",FAA-002
,R.V.2 Standards and Regulatory Compliance,R.V.2.1,Consensus Standards Support,"The organization shall support and comply with applicable consensus standards, including SAE G-34 (ED-324 / ARP6983) and related AI/ML certification guidance.",FAA-003
,R.V.2 Standards and Regulatory Compliance,R.V.2.2,Phased Approval Structure,"The certification approach shall adopt the authority's phased approval structure covering preliminary assessments, compliance demonstration, and final approvals.",FAA-004
,R.V.2 Standards and Regulatory Compliance,R.V.2.3,Leverage Existing Regulations,"The certification strategy shall leverage existing regulations and performance-based requirements where applicable, with justification for any deviations or novel approaches.",FAA-005
,R.V.2 Standards and Regulatory Compliance,R.V.2.4,Overarching Properties as Alternative Means,Overarching Properties (OPs) may be used as alternative means of compliance where traditional objective-based compliance is insufficient or impractical for AI/ML characteristics.,FAA-006
R.F. Federated Learning,R.F.1 Communication and Efficiency,R.F.1.1,Communication Efficiency,The federated learning solution shall meet defined communication efficiency targets compatible with bandwidth and latency constraints of aviation systems.,FL-002
,R.F.1 Communication and Efficiency,R.F.1.2,Operational Feasibility,Time-to-convergence and real-time processing constraints shall meet operational feasibility requirements under representative deployment conditions.,FL-003
,R.F.2 Privacy Preservation,R.F.2.1,Privacy-Preserving Techniques,"Privacy-preserving techniques (e.g., differential privacy, secure aggregation) shall be applied to meet documented privacy requirements without violating minimum performance thresholds.",FL-004
,R.F.3 Security and Attack Resistance,R.F.3.1,FL-Specific Attack Protection,"The system shall be protected against federated learning-specific attacks including inference attacks, gradient leakage, data poisoning, model poisoning, and backdoor attacks under the defined threat model.",FL-005
,R.F.3 Security and Attack Resistance,R.F.3.2,Robust Aggregation,Robust aggregation mechanisms and/or attack detection shall be implemented when threat models require resilience to adversarial or Byzantine clients.,FL-006
,R.F.4 Fairness and Equity,R.F.4.1,Cross-Client Fairness,"The system shall demonstrate fairness across heterogeneous clients and participant groups, with worst-group performance meeting minimum acceptance criteria defined by safety analysis.",FDA-007
,R.F.4 Fairness and Equity,R.F.4.2,Benefit Equity,"Benefits of the federated model (performance improvements, safety enhancements) shall be distributed equitably across clients, with disparities monitored and mitigated.",FL-007
