Metric ID,Metric Name,Metric Definition,Primary Exclusion Reason,Detail,Related Requirement ID(s)
M.CERT.MAINT_RDY,Certification Maintenance Readiness (pass/fail),"Availability of secure data download, retest procedures, and drift workflows to retain certification credit.",Certification Process,Requires certification authority engagement and sustained airworthiness evidence beyond dataset benchmarking scope.,R.L.3.8
M.CERT.PHASE_RDY,Phased Approval Readiness (pass/fail),"Evidence package readiness for preliminary assessment, compliance demonstration, and final approval gates.",Certification Process,Requires phased approval coordination with authority; not measurable via automated dataset evaluation.,R.V.2.2
M.CFG.CONF_CMPL,Configuration Management Conformance (%),Percentage of ML artifacts under version control with reproducible build and change records.,Process & Lifecycle Management,Requires configuration management and version control audit; not derivable from datasets or offline FL simulation.,R.L.1.1
M.CHANGE.CC_INDEX,Change Control Compliance Index,"Composite index of adherence to training, aggregation, validation, deployment approval gates and PCCP criteria.",Process & Lifecycle Management,Requires change control process audit and approval gate evidence; not automatable in benchmarking context.,R.L.2.2; R.L.3.7
M.COTS.DEACT_COV,COTS Function Deactivation Coverage (%),Percentage of unused or out-of-scope COTS functions identified and deactivated or justified with no safety impact.,Process & Lifecycle Management,Requires COTS function deactivation analysis; not applicable to dataset-based benchmarking.,R.L.4.2
M.DATA.ODD_PARAM,ODD Parameterization Completeness (%),"Share of ODD parameters that are explicitly specified, versioned, and approved out of the authoritative ODD parameter list.",Process & Documentation,Requires ODD parameterization documentation audit; not computable from datasets alone.,R.D.1.1
M.DATA.DQR_CONF,Data Quality Conformance Rate (%),"Percentage of Data Quality Requirements (relevance, origin, format, accuracy, integrity, completeness, representativeness) satisfied by audited datasets.",Process & Documentation,Requires data quality audit against documented DQRs; process-level evidence beyond dataset analysis.,R.D.2.1; R.D.2.2
M.DATA.VERIF_COV,Data Verification Coverage (%),Percentage of ODD-appropriateness and adequacy checks executed and passed prior to training.,Process & Documentation,Requires verification coverage audit; process-level evidence beyond dataset metrics.,R.D.2.3
M.DATA.REQ_VAL,Requirements Validation Completion (%),Share of captured requirements validated and signed-off prior to development start.,Process & Documentation,Requires requirements validation sign-off audit; not measurable via datasets.,R.D.2.5
M.HF.SA_INDEX,Situation Awareness Index (individual/shared),Composite SAGAT-like score for individual and shared situation awareness in simulated operational tasks.,Human Factors Evaluation,Requires human-in-the-loop SAGAT testing in simulated tasks; not feasible in automated benchmarking.,R.H.1.1; R.H.1.2
 M.HF.TRAIN_DESKILL,Training Completion & De-Skilling Risk,Completion rate of required training modules and residual de-skilling risk level after mitigation.,Human Factors Evaluation,Requires training completion tracking and de-skilling risk assessment; human factors study required.,R.H.2.1; R.H.2.2
M.LA.PROC_CMPL,Learning Assurance Process Completeness (%),"Percentage of prescribed learning assurance elements documented with roles, activities, and checkpoints.",Process & Lifecycle Management,Requires learning assurance process documentation audit; not derivable from datasets.,R.L.2.1
M.LM.SPEC_CMPL,Learning Management Specification Completeness (%),Percentage of required learning management and training process requirements captured with thresholds.,Process & Lifecycle Management,Requires learning management specification audit; process-level evidence beyond datasets.,R.M.2.1
M.LOCK.POST_DEP,Post-Deployment Learning Disabled (pass/fail),Telemetric and configuration evidence that online learning is disabled in operation unless explicitly approved.,Operational Deployment,Requires telemetric evidence of disabled online learning; operational deployment verification not in benchmarking scope.,R.L.2.3
M.MON.RUNTIME_COV,Runtime Monitoring Coverage Index,"Coverage of ODD bounds monitoring, output confidence monitoring, and metric stability alarms with escalation procedures.",Operational Deployment,Requires runtime monitoring coverage evidence; operational deployment infrastructure not in benchmarking scope.,R.L.3.3; R.L.3.4; R.L.3.5
M.OP.OP_USAGE,Overarching Properties Utilization (pass/fail),Documented use of Overarching Properties as alternative means when traditional objectives are insufficient.,Certification Process,Requires documented use of Overarching Properties; certification strategy evidence beyond datasets.,R.V.2.4
M.OPS.SAFETY_DATA,Operational Safety Data Program Coverage (%),Availability and completeness of operational data recording plus continuous safety assessment cadence adherence.,Operational Deployment,Requires operational safety data recording and continuous assessment program; operational telemetry beyond benchmarking scope.,R.L.3.1; R.L.3.2
M.QA.AUDIT_PASS ,QA Audit Pass Rate (%),Proportion of lifecycle process audits passed without major findings within the audit period.,Process & Lifecycle Management,Requires QA audit execution and pass rate tracking; process audit evidence not in benchmarking scope.,R.L.1.2
M.REG.LEV_TRACE,Regulatory Leverage Traceability (pass/fail),Trace matrix showing which existing regulations and performance-based requirements are used and where deviations occur.,Certification Process,Requires regulatory leverage traceability matrix; certification strategy evidence beyond datasets.,R.V.2.3
M.REUSE.IMPACT_CMPL,Model Reuse Impact Assessment Completeness (%),"Presence and completeness of documented assumptions, limitations, and re-verification for reused or transferred models.",Process & Lifecycle Management,Requires model reuse impact assessment documentation; process audit evidence not in benchmarking scope.,R.L.4.1
M.ROB.STRESS_COV ,Stress Test Coverage (%),Percentage of planned item-to-aircraft interface stress tests executed and passed.,Hardware-in-the-Loop Testing,Requires item-to-aircraft interface stress testing; hardware integration testing beyond dataset benchmarking.,R.M.2.5
M.SAFE.LINK_TRACE,Safety Linkage Traceability (pass/fail),Binary indicator with evidence that metric thresholds are traced to safety objectives and hazard analysis.,Process & Documentation,Requires safety linkage traceability documentation audit; process-level evidence beyond datasets.,R.M.1.1
 M.SAFE.HAZ_PRIOR,Hazard-Driven Prioritization Factor,Ratio of FN to FP stringency in acceptance limits as justified by hazard analysis.,Process & Documentation,Requires hazard-driven prioritization justification documentation; safety analysis evidence beyond datasets.,R.M.1.2
M.SEC.RISK_COV,Security Risk Coverage (%),Coverage of identified AI/ML-specific threats with mapped mitigations validated for effectiveness.,Operational Deployment,Requires security threat coverage evidence and mitigation validation; operational security assessment beyond benchmarking.,R.D.5.1; R.D.5.2
M.STD.STD_COMP,Consensus Standards Compliance (%),Percentage of applicable clauses from referenced consensus standards implemented with evidence.,Certification Process,Requires consensus standards compliance documentation audit; certification evidence beyond datasets.,R.V.2.1
M.SYS.FUNC_TRACE,Functional Decomposition Traceability (%),Proportion of decomposed functions correctly allocated with trace links to implementation artifacts acknowledging ML-specific breaks in hierarchy.,Process & Documentation,Requires functional decomposition traceability documentation; systems engineering audit beyond datasets.,R.D.3.1
M.SYS.AILVL_SET,AI Involvement Level Determination (pass/fail),Binary indicator with evidence that AI Involvement Level was defined and approved with rationale.,Process & Documentation,Requires AI Involvement Level determination documentation; process audit evidence beyond datasets.,R.D.3.2
M.TRACE.BIDIR,Traceability Completeness (%),"Share of requirements with bidirectional links to data, model, V&V cases, and results.",Process & Documentation,Requires bidirectional traceability matrix audit; process-level evidence beyond datasets.,R.L.1.3
M.TRUST.ETHICS_IDX,Trustworthiness & Ethics Compliance Index,"Checklist score across safety, lawfulness, robustness, ethics, bias controls, and data protection compliance.",Process & Documentation,Requires trustworthiness checklist audit across multiple domains; process and ethics audit beyond datasets.,R.D.4.1; R.D.4.2; R.D.4.3
M.VV.OBJ_COV,V&V Objective Coverage (%),"Coverage of explainability, predictability, auditability, and traceability objectives with executed tests and evidence.",Process & Documentation,Requires V&V objective coverage documentation audit; verification process evidence beyond datasets.,R.V.1.1
 M.XAI.USE_SCORE,Explanation Usability Score,"Task-based human factors score for clarity and relevance of explanations of model scope, behavior, outputs, and uncertainty.",Human Factors Evaluation,Requires human factors usability testing; not feasible in automated benchmarking without user studies.,R.E.1.1
 M.XAI.DOC_CMPL,Explanation Documentation Completeness (%),"Presence of method specs, configurations, data scope, and known limitations in explainability documentation.",Process & Documentation,Requires explainability documentation completeness audit; process-level evidence beyond datasets.,R.E.1.3
M.XAI.CLARITY_RATE,Presentation Clarity Pass Rate (%),Share of explanatory outputs rated clear and unambiguous by end users in representative tasks.,Human Factors Evaluation,Requires end-user clarity rating in representative tasks; human evaluation not feasible in automated benchmarking.,R.E.1.4
M.XAI.VALID_COV,Explanation Validity Coverage (%),Fraction of relevant outputs for which the specified explanation type has been validity-checked with evidence.,Process & Documentation,Requires explanation validity documentation audit; process-level evidence beyond datasets.,R.E.1.5
M.ARCH.DOC_SCORE ,Architecture Documentation Score,Presence and completeness of architecture documentation for all model constituents.,Process & Documentation,"This metric depends entirely on the presence and completeness of system and architecture documentation, which are created and assessed via manual review processes.",R.D.3.3
M.FLOW.TRACE_IDX,"Flowdown Traceability Index	","Fraction of derived requirements mapped and evidenced to subsystem processes.	",Process & Documentation,"Requirement flowdown mapping is tracked through project management tools or manual traceability audits, not within the scope of learning pipelines, model code, or datasets. ",R.D.3.4
M.IMP.SAFE_IMPACT,Derived Requirement Safety Impact Coverage,Proportion of derived requirements that have an explicitly documented safety impact assessment and updated links to the safety assessment and affected subsystem requirements.,Process & Documentation,"This metric depends on reviewing safety assessment documentation and traceability links between derived requirements and safety analyses. It cannot be computed from datasets or FL benchmark runs and therefore is excluded from benchmark evaluation.

",R.D.3.5
